\documentclass[journal]{IEEEtran}

%\usepackage{ifpdf}
\usepackage{cite}
%\usepackage[pdftex]{graphicx}
%\usepackage[cmex10]{amsmath}
%\usepackage{algorithmic}
%\usepackage{array}
%\usepackage[caption=false,font=footnotesize]{subfig}
%\usepackage{fixltx2e}
%\usepackage{stfloats}
%\usepackage{dblfloatfix}
\usepackage{url}
\hyphenation{op-tical net-works semi-conduc-tor}

\begin{document}
\title{Hypercolumn-array Based Image Representation and 
Its Application to Shape-based Object Detection}
\author{Hui~Wei\thanks{Hui~Wei is with the School of Computer Science, 
Laboratory of Cognitive Modeling and Algorithms, 
Brain Science Research Center, Fudan University, Shanghai, China. 
Corresponding author's email: weihui@fudan.edu.cn.},
Zheng~Dong\thanks{Zheng~Dong and Qiang~Li are with the School of Computer Science, 
Laboratory of Cognitive Modeling and Algorithms, 
Fudan University, Shanghai, China.},
and~Qiang~Li}

% The paper headers
%\markboth{Journal of \LaTeX\ Class Files,~Vol.~13, No.~9, September~2014}%
%{Shell \MakeLowercase{\textit{et al.}}: Bare Demo of IEEEtran.cls for Journals}
%\IEEEpubid{0000--0000/00\$00.00~\copyright~2014 IEEE}
% Remember, if you use this you must call \IEEEpubidadjcol in the second
% column for its text to clear the IEEEpubid mark.

% make the title area
\maketitle

\begin{abstract}
Machine learning is perhaps the most popular strategy currently employed in object recognition. 
The strategy typically uses a high-dimensional vector to describe an image, 
and applies some classification algorithm to isolate positive areas apart from negative areas. 
While the advantage of this strategy is its architectural simplicity, 
it simultaneously suffers from computational complexity, fragile representation, 
unguaranteed generalization, black arts in optimization, and so on. 
In comparison with low-order features, such as color or gradient, contour is more stable and persistent; 
therefore, shape-based methods take account of a greater number of essential aspects for object recognition. 
Biological and psychological evidence increasingly reveals that geometrical and topological features are the keys to object recognition. 
Although these types of high-level features are not easily obtained, 
their discriminating abilities greatly improve the efficiency of perception. 
Attracted by the excellent performance of neural visual systems for shape processing, 
we simulate the mechanism of hypercolumns in the V1 cortex of mammals that selectively responds to bar stimuli, 
and design an orderly-arranged array to extract and represent all possible linear or near-linear stimuli in an image. 
Each unit of this array can cover all orientation stimuli occurring over a certain small area. 
These effective units together produce a type of low-dimensional vector to describe shape. 
Based on the neighborhood of units in the array, 
we construct a graph whose node represents a short line segment with a certain position and slope. 
Therefore, any segment of contour, i.e., a curve, in an edge image might be a route in that graph. 
The most significant thing here is that a graph converts an image, comprised of typically unstructured raw data, 
into structured and semantic-enriched data. 
We search along the routes in that graph and compare them with a shape template for object detection. 
Organizing segments of contour into a graph greatly upgrades the level of image representation, 
remarkably reduces the load of combinations, significantly improves the efficiency of object searching, 
and facilitates the intervening of high-level knowledge. 
This work provides a systematic infrastructure for shape-based models.
\end{abstract}

% Note that keywords are not normally used for peerreview papers.
\begin{IEEEkeywords}
orientation column, shape representation, object recognition, primary visual cortex.
\end{IEEEkeywords}

\IEEEpeerreviewmaketitle

\section{Introduction}

% needed in second column of first page if using \IEEEpubid
%\IEEEpubidadjcol

\IEEEPARstart{D}{etecting} 
an object within a complex background is still one of the major challenges of pattern recognition and computer vision. 
The difficulty lies in the conditions of image capture,
where images are captured under different illumination conditions, 
from different distances, and, sometimes, with overlapping objects.
These variations make an object's appearance, either in size, in posture, or in color, endless changing. 
While machine learning is arguably the most popular strategy currently employed in object recognition, 
the uncertainties associated with an ever changing environment and limited training create numerous difficulties for machine learning methods to achieve efficient object recognition. 
As such, obtaining an efficient, stable, and convenient method of representing features becomes the key requirement of object recognition in the real-world. 
The most stable characteristic of an object is its contour. 
The shapes or contours of most rigid objects tend to remain invariant regardless of a changing environment. 
Therefore, an object's shape or contour represents the most promising feature for efficient object recognition.


The primary visual cortex, which is also known as V1, locates in the striate cortex of mammals.
It is the best-studied visual area in the brain.
In this paper, we simulate the neural mechanism of V1 because this area contains many orderly-arranged hypercolumns that represent the orientation information of a visual stimulus.
This biological infrastructure provides a feasible entity to record object contours. 
We therefore design and train a self-organizing map (SOM) to extract the line information of an image. 
Under this approach, any line, regardless of its position, length, or slope, 
will activate one or more orientation-sensitive neurons, 
so an edge-image will be re-described by a set of active neurons. 
Based on this line-representing platform, 
we propose a contour-matching algorithm that uses geometrical characteristics to recognize objects. 
This provides good performance in environment adaptation and better generalization.

The remainder of this paper has been organized as follows. 
Section 2 reviews some related studies in shape-based object recognition and visual neurobiological mechanism simulation. 
The advantages and disadvantages of the main features of each study are briefly discussed. 
Section 3 presents the training process involving orientation columns, 
and how an image is represented by an array of artificial orientation columns. 
Section 4 describes how an edge image is converted into an undirected graph, 
and how route searching is conducted for this graph. 
Section 5 presents the method of similarity matching between routes and templates, 
and how this method is applied to the recognition of objects in real images. 
Experimental results are presented in Section 6, which is divided into two parts. 
Part one analyzes the capability for image representation and reduction provided by the proposed array of artificial orientation columns. 
Part two presents the recognition results obtained for some real image datasets. 
The final section presents conclusions and future expectations.

\section{Related Work}

Here, we divide the discussion of related work into two components. 
One component concerns the modeling of the V1 area, 
whereas the other component is concerned with shape- or contour-based object recognition methods. 

\subsection{V1 simulation research}

A number of approaches to the computational modeling of the neural mechanism of the V1 area of mammals have been proposed. 
The differences between these approaches lie in their points of focus, 
where some approaches focus on pathway, some on mechanism, and some on computation. 
Some studies have concentrated on the visual neural pathway 
\cite{bickle1999,shariati2012,nakagama2004,harvey2008}. 
For example, Bickle et al. \cite{bickle1999} proposed an artificial neural network with interactive activation and competition (IAC) mechanism by reference to the lateral geniculate nucleus (LGN), 
which is the direct pathway from the primary visual cortex to the thalamus, 
to implement several functions of the visual cortex. 
Shariati et al. \cite{shariati2012} simulated the entire neural pathway from a photoreceptor in the retina to the second sub-layer of the primary visual cortex. 
Some studies have concentrated on visual neurocomputing problems 
\cite{curuklu2002,wang2011,li2005,mihalas2011,ramirez2013}. 
For example, Curuklu \cite{curuklu2002} proposed a Bayesian confidence propagation neural network (BCPNN) to simulate a hypercolumn, which is the functional unit of the visual cortex. 
Wang et al. \cite{wang2011} used sparse coding and a back-propagation (BP) neural network to model the primary visual cortex. 
Finally, a number of studies have concentrated on the functional roles of variant neurons in the visual system \cite{okamoto2004,willmore2012,bednar2012,law2011,giacomantonio2010,zhao2010,yan2012,piech2013,song2013}. 
Okamoto \cite{okamoto2004} designed a honeycomb-like model based on a mechanism of short-range horizontal connections to explain the topological characteristics of the V1 area. 
Willmore \cite{willmore2012} successfully simulated the visual cortex based on Hebbian and anti-Hebbian rules. 
Bednar et al. \cite{bednar2012,law2011} implemented a gain-controlled, adaptive, 
and lateral-connected model that specialized the function of every neuron in the pathway, 
and simulated the primary visual cortex more completely. 
The above studies were able to realize some neural circuits and partial functions of the V1 area.
However, they did not sufficiently account for real image representation, 
which is the ultimate and most important function of the V1 area. 
In fact, all subsequent processing, such as object recognition and scene understanding, 
begins in the V1 area. 
Above all, these studies lacked the crucial consideration of how the V1's output meets the demands of subsequent recognition tasks. 
This constitutes one of the main goals of the present study.

\subsection{Shape- or contour-based object recognition}

Shape- or contour-based object recognition research has a long history. 
In the early stage, chamfer matching \cite{borgefors1988,shotton2005,thayananthan2003,opelt2006} 
was a frequently-used method that converted an original image into a depth image, 
and searched for the point with the best match. 
This method demonstrated a certain adaptability. 
As an additional aid, an image pyramid was designed to achieve scale invariance \cite{borgefors1988}. 
However, this method usually exhibits high time complexity and has a low tolerance to background interference. 
To address this problem, several new variants of the chamfer matching method have been proposed in recent years. 
For example, Shotton \cite{shotton2005} designed an oriented chamfer matching model, 
Thayananthan \cite{thayananthan2003} combined this method with a shape context descriptor, 
and Opelt \cite{thayananthan2003} added AdaBoost. 
These variants were observed to improve the efficiency and recognition rate.

Another type of shape-based method is mainly based on contour segment matching between templates and real images. 
This type of method firstly converts an image into edges, 
and then fits curves or line segments to the edge pixels. 
Subsequently, the set of curves or line segments are represented with some geometrical feature descriptors. Finally, the similarity between the set of segments and shape templates are obtained. 
Once matching pairs between line segments and the template are established, 
some guesses can be made to estimate the possible positions for the target object, 
and then verify these possible positions one-by-one. 
This type of method can be further divided into two categories. 
One is the dominant-set method and the other is the partial-match method. 
Pavan \cite{pavan2007} proposed the dominant-set method for finding the principle corresponding components in two sets. 
Yang \cite{yang2012} used this method to form a scale invariant global shape similarity estimation to match between template contour parts and image edge fragments. 
Partial-match methods \cite{ma2011,riemenschneider2010,liu2010} are similar to dominant-set methods. 
Ma \cite{ma2011} obtained a similarity matrix based on the angles of edges in a contour and maximized the similarity between classes through Liu's cluster algorithm \cite{liu2010}. 
Objects were then recognized by seeking the largest community. 
Differing from the work of Ma \cite{ma2011}, 
in the stage of evaluation, Riemenschneider \cite{riemenschneider2010} estimated the object position using the pyramid matching kernel (PMK) algorithm after conducting contour segment matching. 
Methods proposed in \cite{zhu2008,srinivasan2010} introduced a shape context descriptor. 
Zhu \cite{zhu2008} used linear programming to find a one-to-one mapping between the image and the template. 
Srinivasan \cite{srinivasan2010} developed this method further by introducing a bottom-up process to optimize many-to-one mapping results. 
In general all these methods exhibit high time complexity subject to exhaustive comparison between real-world images and templates.

% An example of a floating figure using the graphicx package.
% Note that \label must occur AFTER (or within) \caption.
% For figures, \caption should occur after the \includegraphics.
% Note that IEEEtran v1.7 and later has special internal code that
% is designed to preserve the operation of \label within \caption
% even when the captionsoff option is in effect. However, because
% of issues like this, it may be the safest practice to put all your
% \label just after \caption rather than within \caption{}.
%
% Reminder: the "draftcls" or "draftclsnofoot", not "draft", class
% option should be used if it is desired that the figures are to be
% displayed while in draft mode.
%
%\begin{figure}[!t]
%\centering
%\includegraphics[width=2.5in]{myfigure}
% where an .eps filename suffix will be assumed under latex, 
% and a .pdf suffix will be assumed for pdflatex; or what has been declared
% via \DeclareGraphicsExtensions.
%\caption{Simulation results for the network.}
%\label{fig_sim}
%\end{figure}

% Note that IEEE typically puts floats only at the top, even when this
% results in a large percentage of a column being occupied by floats.


% An example of a double column floating figure using two subfigures.
% (The subfig.sty package must be loaded for this to work.)
% The subfigure \label commands are set within each subfloat command,
% and the \label for the overall figure must come after \caption.
% \hfil is used as a separator to get equal spacing.
% Watch out that the combined width of all the subfigures on a 
% line do not exceed the text width or a line break will occur.
%
%\begin{figure*}[!t]
%\centering
%\subfloat[Case I]{\includegraphics[width=2.5in]{box}%
%\label{fig_first_case}}
%\hfil
%\subfloat[Case II]{\includegraphics[width=2.5in]{box}%
%\label{fig_second_case}}
%\caption{Simulation results for the network.}
%\label{fig_sim}
%\end{figure*}
%
% Note that often IEEE papers with subfigures do not employ subfigure
% captions (using the optional argument to \subfloat[]), but instead will
% reference/describe all of them (a), (b), etc., within the main caption.
% Be aware that for subfig.sty to generate the (a), (b), etc., subfigure
% labels, the optional argument to \subfloat must be present. If a
% subcaption is not desired, just leave its contents blank,
% e.g., \subfloat[].


% An example of a floating table. Note that, for IEEE style tables, the
% \caption command should come BEFORE the table and, given that table
% captions serve much like titles, are usually capitalized except for words
% such as a, an, and, as, at, but, by, for, in, nor, of, on, or, the, to
% and up, which are usually not capitalized unless they are the first or
% last word of the caption. Table text will default to \footnotesize as
% IEEE normally uses this smaller font for tables.
% The \label must come after \caption as always.
%
%\begin{table}[!t]
%% increase table row spacing, adjust to taste
%\renewcommand{\arraystretch}{1.3}
% if using array.sty, it might be a good idea to tweak the value of
% \extrarowheight as needed to properly center the text within the cells
%\caption{An Example of a Table}
%\label{table_example}
%\centering
%% Some packages, such as MDW tools, offer better commands for making tables
%% than the plain LaTeX2e tabular which is used here.
%\begin{tabular}{|c||c|}
%\hline
%One & Two\\
%\hline
%Three & Four\\
%\hline
%\end{tabular}
%\end{table}


% Note that the IEEE does not put floats in the very first column
% - or typically anywhere on the first page for that matter. Also,
% in-text middle ("here") positioning is typically not used, but it
% is allowed and encouraged for Computer Society conferences (but
% not Computer Society journals). Most IEEE journals/conferences use
% top floats exclusively. 
% Note that, LaTeX2e, unlike IEEE journals/conferences, places
% footnotes above bottom floats. This can be corrected via the
% \fnbelowfloat command of the stfloats package.




\section{Conclusion}
The conclusion goes here.





% if have a single appendix:
%\appendix[Proof of the Zonklar Equations]
% or
%\appendix  % for no appendix heading
% do not use \section anymore after \appendix, only \section*
% is possibly needed

% use appendices with more than one appendix
% then use \section to start each appendix
% you must declare a \section before using any
% \subsection or using \label (\appendices by itself
% starts a section numbered zero.)
%


\appendices
\section{Proof of the First Zonklar Equation}
Appendix one text goes here.

% you can choose not to have a title for an appendix
% if you want by leaving the argument blank
\section{}
Appendix two text goes here.


% use section* for acknowledgment
\section*{Acknowledgment}


The authors would like to thank...


% Can use something like this to put references on a page
% by themselves when using endfloat and the captionsoff option.
\ifCLASSOPTIONcaptionsoff
  \newpage
\fi



% trigger a \newpage just before the given reference
% number - used to balance the columns on the last page
% adjust value as needed - may need to be readjusted if
% the document is modified later
%\IEEEtriggeratref{8}
% The "triggered" command can be changed if desired:
%\IEEEtriggercmd{\enlargethispage{-5in}}

% references section

% can use a bibliography generated by BibTeX as a .bbl file
% BibTeX documentation can be easily obtained at:
% http://www.ctan.org/tex-archive/biblio/bibtex/contrib/doc/
% The IEEEtran BibTeX style support page is at:
% http://www.michaelshell.org/tex/ieeetran/bibtex/
\bibliographystyle{IEEEtran}
% argument is your BibTeX string definitions and bibliography database(s)
\bibliography{ref}
%
% <OR> manually copy in the resultant .bbl file
% set second argument of \begin to the number of references
% (used to reserve space for the reference number labels box)
%\begin{thebibliography}{1}
%
%\bibitem{IEEEhowto:kopka}
%H.~Kopka and P.~W. Daly, \emph{A Guide to \LaTeX}, 3rd~ed.\hskip 1em plus
%  0.5em minus 0.4em\relax Harlow, England: Addison-Wesley, 1999.
%
%\end{thebibliography}

% biography section
% 
% If you have an EPS/PDF photo (graphicx package needed) extra braces are
% needed around the contents of the optional argument to biography to prevent
% the LaTeX parser from getting confused when it sees the complicated
% \includegraphics command within an optional argument. (You could create
% your own custom macro containing the \includegraphics command to make things
% simpler here.)
%\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{mshell}}]{Michael Shell}
% or if you just want to reserve a space for a photo:

\begin{IEEEbiography}{Michael Shell}
Biography text here.
\end{IEEEbiography}

% if you will not have a photo at all:
\begin{IEEEbiographynophoto}{John Doe}
Biography text here.
\end{IEEEbiographynophoto}

% insert where needed to balance the two columns on the last page with
% biographies
%\newpage

\begin{IEEEbiographynophoto}{Jane Doe}
Biography text here.
\end{IEEEbiographynophoto}

% You can push biographies down or up by placing
% a \vfill before or after them. The appropriate
% use of \vfill depends on what kind of text is
% on the last page and whether or not the columns
% are being equalized.

%\vfill

% Can be used to pull up biographies so that the bottom of the last one
% is flush with the other column.
%\enlargethispage{-5in}



% that's all folks
\end{document}


